
@inproceedings{anuApproachRecommendationVerbosity2019,
  title = {An {{Approach}} to {{Recommendation}} of {{Verbosity Log Levels Based}} on {{Logging Intention}}},
  booktitle = {2019 {{IEEE International Conference}} on {{Software Maintenance}} and {{Evolution}} ({{ICSME}})},
  author = {Anu, Han and Chen, Jie and Shi, Wenchang and Hou, Jianwei and Liang, Bin and Qin, Bo},
  date = {2019-09},
  pages = {125--134},
  issn = {1063-6773},
  doi = {10.1109/ICSME.2019.00022},
  abstract = {Verbosity levels of logs are designed to discriminate highly diverse runtime events, which facilitates system failure identification through simple keyword search (e.g., fatal, error). Verbosity levels should be properly assigned to logging statements, as inappropriate verbosity levels would confuse users and cause a lot of redundant maintenance effort. However, to achieve such a goal is not an easy task due to the lack of practical specifications and guidelines towards verbosity log level usages. The existing research has built a classification model on log related quantitative metrics such as log density to improve logging level practice. Though such quantitative metrics can reveal logging characteristics, their contributions on logging level decision are limited, since valuable logging intention information buried in logging code context can not be captured. In this paper, we propose an automatic approach to help developers determine the appropriate verbosity log levels. More specially, our approach discriminates different verbosity log level usages based on code context features that contain underlying logging intention. To validate our approach, we implement a prototype tool, VerbosityLevelDirector, and perform a case study to measure its effectiveness on four well-known open source software projects. Evaluation results show that VerbosityLevelDirector achieves high performance on verbosity level discrimination and outperforms the baseline approaches on all those projects. Furthermore, through applying noise handling technique, our approach can detect previously unknown inappropriate verbosity level configurations in the code repository. We have reported 21 representative logging level errors with modification advice to issue tracking platforms of the examined software projects and received positive feedback from their developers. The above results confirm that our work can help developers make a better logging level decision in real-world engineering.},
  eventtitle = {2019 {{IEEE International Conference}} on {{Software Maintenance}} and {{Evolution}} ({{ICSME}})},
  file = {C\:\\Users\\bollich_k\\Zotero\\storage\\W9UZ892D\\8919094.html},
  keywords = {21 representative logging level errors,appropriate verbosity log levels,feature extraction,Feature extraction,inappropriate verbosity levels,Libraries,log density,log related quantitative metrics,logging characteristics,logging context feature,logging intention,logging level decision,logging level practice,logging statements,Measurement,noise handling technique,program diagnostics,public domain software,Runtime,Software,software maintenance,software metrics,static code analysis,Task analysis,Tools,underlying logging intention,unknown inappropriate verbosity level configurations,valuable logging intention information,verbosity level discrimination,verbosity log level usages}
}

@online{apacheApacheLog4netApache,
  title = {Apache Log4net – {{Apache}} Log4net: {{Home}} - {{Apache}} Log4net},
  author = {Apache},
  url = {https://logging.apache.org/log4net/},
  urldate = {2020-05-19},
  file = {C\:\\Users\\bollich_k\\Zotero\\storage\\4G4HNC3W\\log4net.html}
}

@online{aug13LoggingNETModernday2019,
  title = {Logging in {{C}}\# .{{NET Modern}}-Day {{Practices}}: {{The Complete Guide}}},
  shorttitle = {Logging in {{C}}\# .{{NET Modern}}-Day {{Practices}}},
  author = {Aug 13 and C\# | 27, 2019 |},
  date = {2019-08-13T08:27:56+00:00},
  journaltitle = {Michael's Coding Spot},
  url = {https://michaelscodingspot.com/logging-in-dotnet/},
  urldate = {2020-05-15},
  abstract = {Logging is a big part of software development for many years now. This guide is a bird's eye view of modern solutions for logging in .NET space.},
  file = {C\:\\Users\\bollich_k\\Zotero\\storage\\ZHKYGBLY\\logging-in-dotnet.html},
  langid = {american}
}

@online{BesserZentralProfessionelles,
  title = {Besser zentral: Professionelles Logging | heise Developer},
  shorttitle = {Besser zentral},
  url = {https://www.heise.de/developer/artikel/Besser-zentral-Professionelles-Logging-2532864.html},
  urldate = {2020-03-31},
  file = {C\:\\Users\\bollich_k\\Zotero\\storage\\F4PGH8Z9\\Besser-zentral-Professionelles-Logging-2532864.html},
  langid = {german}
}

@book{buchLoggingSchnelleinstieg2014,
  title = {Logging: Schnelleinstieg},
  shorttitle = {Logging},
  author = {Buch, Jonathan and Arrasz, Joachim and van Lessen, Tammo},
  date = {2014-11-16},
  publisher = {{entwickler.press}},
  abstract = {Logging beschreibt das Speichern von Prozessen und Datenänderungen in so genannten Logdateien. Dieser shortcut liefert eine Einführung ins Thema Logging. Er zeigt die Wichtigkeit einer engen Kooperation zwischen Entwicklern und Betreibern für den Start einer Softwareentwicklung auf. Dabei geht er auf die Komponenten ein, die man unbedingt im Blick haben sollte, um ein Projekt möglichst effizient zu gestalten. Des Weiteren beleuchtet der shortcut den Erfolg eines Systems und die Nachverfolgung von Problemen. Logs geben Aufschluss über den Verlauf von Ereignissen, jedoch im Grunde nicht über den Zustand einer Anwendung. Durch das Erfassen von Anwendungs- und Systemmetriken können allerdings Muster herauskristallisiert und Problemzusammenhänge leichter identifiziert werden.},
  langid = {Deutsch},
  pagetotal = {27}
}

@book{cCleanCodeHandbook2008,
  title = {Clean {{Code}}: {{A Handbook}} of {{Agile Software Craftsmanship}}},
  shorttitle = {Clean {{Code}}},
  author = {C, Martin Robert},
  date = {2008-08-01},
  edition = {1},
  publisher = {{Pearson}},
  abstract = {Even bad code can function. But if code isn’t clean, it can bring a development organization to its knees. Every year, countless hours and significant resources are lost because of poorly written code. But it doesn’t have to be that way. Noted software expert Robert C. Martin presents a revolutionary paradigm with  Clean Code: A Handbook of Agile Software Craftsmanship . Martin has teamed up with his colleagues from Object Mentor to distill their best agile practice of cleaning code “on the fly” into a book that will instill within you the values of a software craftsman and make you a better programmer—but only if you work at it. What kind of work will you be doing? You’ll be reading code—lots of code. And you will be challenged to think about what’s right about that code, and what’s wrong with it. More importantly, you will be challenged to reassess your professional values and your commitment to your craft.   Clean Code  is divided into three parts. The first describes the principles, patterns, and practices of writing clean code. The second part consists of several case studies of increasing complexity. Each case study is an exercise in cleaning up code—of transforming a code base that has some problems into one that is sound and efficient. The third part is the payoff: a single chapter containing a list of heuristics and “smells” gathered while creating the case studies. The result is a knowledge base that describes the way we think when we write, read, and clean code. Readers will come away from this book understanding  How to tell the difference between good and bad code How to write good code and how to transform bad code into good code How to create good names, good functions, good objects, and good classes How to format code for maximum readability How to implement complete error handling without obscuring code logic How to unit test and practice test-driven development This book is a must for any developer, software engineer, project manager, team lead, or systems analyst with an interest in producing better code.},
  langid = {english},
  pagetotal = {447}
}

@inproceedings{chenCharacterizingDetectingAntipatterns2017,
  title = {Characterizing and Detecting Anti-Patterns in the Logging Code},
  booktitle = {Proceedings of the 39th {{International Conference}} on {{Software Engineering}}},
  author = {Chen, Boyuan and Jiang, Zhen Ming (Jack)},
  date = {2017-05-20},
  pages = {71--81},
  publisher = {{IEEE Press}},
  location = {{Buenos Aires, Argentina}},
  doi = {10.1109/ICSE.2017.15},
  url = {https://doi.org/10.1109/ICSE.2017.15},
  urldate = {2020-04-15},
  abstract = {Snippets of logging code are output statements (e.g., LOG.info or System.out.println) that developers insert into a software system. Although more logging code can provide more execution context of the system's behavior during runtime, it is undesirable to instrument the system with too much logging code due to maintenance overhead. Furthermore, excessive logging may cause unexpected side-effects like performance slow-down or high disk I/O bandwidth. Recent studies show that there are no well-defined coding guidelines for performing effective logging. Previous research on the logging code mainly tackles the problems of where-to-log and what-to-log. There are very few works trying to address the problem of how-to-log (developing and maintaining high-quality logging code). In this paper, we study the problem of how-to-log by characterizing and detecting the anti-patterns in the logging code. As the majority of the logging code is evolved together with the feature code, the remaining set of logging code changes usually contains the fixes to the anti-patterns. We have manually examined 352 pairs of independently changed logging code snippets from three well-maintenance open source systems: ActiveMQ, Hadoop and Maven. Our analysis has resulted in six different anti-patterns in the logging code. To demonstrate the value of our findings, we have encoded these anti-patterns into a static code analysis tool, LCAnalyzer. Case studies show that LCAnalyzer has an average recall of 95\% and precision of 60\% and can be used to automatically detect previously unknown anti-patterns in the source code. To gather feedback, we have filed 64 representative instances of the logging code anti-patterns from the most recent releases of ten open source software systems. Among them, 46 instances (72\%) have already been accepted by their developers.},
  file = {C\:\\Users\\bollich_k\\Zotero\\storage\\ME9W5P3G\\Chen und Jiang - 2017 - Characterizing and detecting anti-patterns in the .pdf},
  isbn = {978-1-5386-3868-2},
  keywords = {anti-patterns,empirical studies,logging code,logging practices,software maintenance},
  series = {{{ICSE}} '17}
}

@article{chenCharacterizingLoggingPractices2017,
  title = {Characterizing Logging Practices in {{Java}}-Based Open Source Software Projects – a Replication Study in {{Apache Software Foundation}}},
  author = {Chen, Boyuan and (Jack) Jiang, Zhen Ming},
  date = {2017-02-01},
  journaltitle = {Empirical Software Engineering},
  shortjournal = {Empir Software Eng},
  volume = {22},
  pages = {330--374},
  issn = {1573-7616},
  doi = {10.1007/s10664-016-9429-5},
  url = {https://doi.org/10.1007/s10664-016-9429-5},
  urldate = {2020-06-16},
  abstract = {Log messages, which are generated by the debug statements that developers insert into the code at runtime, contain rich information about the runtime behavior of software systems. Log messages are used widely for system monitoring, problem diagnoses and legal compliances. Yuan et al. performed the first empirical study on the logging practices in open source software systems. They studied the development history of four C/C++ server-side projects and derived ten interesting findings. In this paper, we have performed a replication study in order to assess whether their findings would be applicable to Java projects in Apache Software Foundations. We examined 21 different Java-based open source projects from three different categories: server-side, client-side and supporting-component. Similar to the original study, our results show that all projects contain logging code, which is actively maintained. However, contrary to the original study, bug reports containing log messages take a longer time to resolve than bug reports without log messages. A significantly higher portion of log updates are for enhancing the quality of logs (e.g., formatting \& style changes and spelling/grammar fixes) rather than co-changes with feature implementations (e.g., updating variable names).},
  langid = {english},
  number = {1}
}

@inproceedings{chenImprovingSoftwareLogging2019,
  title = {Improving the {{Software Logging Practices}} in {{DevOps}}},
  booktitle = {2019 {{IEEE}}/{{ACM}} 41st {{International Conference}} on {{Software Engineering}}: {{Companion Proceedings}} ({{ICSE}}-{{Companion}})},
  author = {Chen, Boyuan},
  date = {2019-05},
  pages = {194--197},
  issn = {2574-1926},
  doi = {10.1109/ICSE-Companion.2019.00080},
  abstract = {DevOps refers to a set of practices dedicated to accelerating modern software engineering process. It breaks the barriers between software development and IT operations and aims to produce and maintain high quality software systems. Software logging is widely used in DevOps. However, there are few guidelines and tool support for composing high quality logging code and current application context of log analysis is very limited with respect to feedback for developers and correlations among other telemetry data. This thesis proposes automated approaches to improving software logging practices in DevOps by leveraging various types of software repositories (e.g., historical, communication, bug, and runtime repositories). We aim to support the software development side by providing guidelines and tools on developing and maintaining high quality logging code. We aim to support the IT operation side by enriching the log analysis context through systematic estimating code coverage via executing logs and in-depth problem diagnosis by correlating logs with other telemetry data (e.g., traces and APM data). Case studies show that our approaches can provide useful software logging suggestions to both developers and operators in open source and commercial systems.},
  eventtitle = {2019 {{IEEE}}/{{ACM}} 41st {{International Conference}} on {{Software Engineering}}: {{Companion Proceedings}} ({{ICSE}}-{{Companion}})},
  file = {C\:\\Users\\bollich_k\\Zotero\\storage\\XZUKR8FN\\8802761.html},
  keywords = {commercial systems,DevOps,empirical studies,high quality logging code,high quality software systems,log analysis context,logging code,logging practices,modern software engineering process,open source systems,software development,software logging practices,software quality,software repositories,system monitoring,telemetry data}
}

@book{chuvakinLoggingLogManagement2012,
  title = {Logging and Log Management: The Authoritative Guide to Understanding the Concepts Surrounding Logging and Log Management},
  shorttitle = {Logging and Log Management},
  author = {Chuvakin, Anton and Schmidt, Kevin and Phillips, Chris},
  date = {2012-12-13},
  edition = {1},
  publisher = {{Syngress}},
  abstract = {Logging and Log Management: The Authoritative Guide to Understanding the Concepts Surrounding Logging and Log Management introduces information technology professionals to the basic concepts of logging and log management. It provides tools and techniques to analyze log data and detect malicious activity. The book consists of 22 chapters that cover the basics of log data; log data sources; log storage technologies; a case study on how syslog-ng is deployed in a real environment for log collection; covert logging; planning and preparing for the analysis log data; simple analysis techniques; and tools and techniques for reviewing logs for potential problems. The book also discusses statistical analysis; log data mining; visualizing log data; logging laws and logging mistakes; open source and commercial toolsets for log data collection and analysis; log management procedures; and attacks against logging systems. In addition, the book addresses logging for programmers; logging and compliance with regulations and policies; planning for log analysis system deployment; cloud logging; and the future of log standards, logging, and log analysis. This book was written for anyone interested in learning more about logging and log management. These   include systems administrators, junior security engineers, application developers, and managers.Comprehensive coverage of log management including analysis, visualization, reporting and moreIncludes information on different uses for logs -- from system operations to regulatory complianceFeatures case Studies on syslog-ng and actual real-world situations where logs came in handy in incident responseProvides practical guidance in the areas of report, log analysis system selection, planning a log analysis system and log data normalization and correlation},
  langid = {Englisch},
  pagetotal = {464}
}

@article{cinqueEventLogsAnalysis2013,
  title = {Event {{Logs}} for the {{Analysis}} of {{Software Failures}}: {{A Rule}}-{{Based Approach}}},
  shorttitle = {Event {{Logs}} for the {{Analysis}} of {{Software Failures}}},
  author = {Cinque, Marcello and Cotroneo, Domenico and Pecchia, Antonio},
  date = {2013},
  journaltitle = {IEEE Transactions on Software Engineering},
  doi = {10.1109/TSE.2012.67},
  abstract = {Event logs have been widely used over the last three decades to analyze the failure behavior of a variety of systems. Nevertheless, the implementation of the logging mechanism lacks a systematic approach and collected logs are often inaccurate at reporting software failures: This is a threat to the validity of log-based failure analysis. This paper analyzes the limitations of current logging mechanisms and proposes a rule-based approach to make logs effective to analyze software failures. The approach leverages artifacts produced at system design time and puts forth a set of rules to formalize the placement of the logging instructions within the source code. The validity of the approach, with respect to traditional logging mechanisms, is shown by means of around 12,500 software fault injection experiments into real-world systems.}
}

@online{DatenschutzgrundverordnungDSGVOBewaeltigung,
  title = {Datenschutzgrundverordnung (DSGVO): Bewältigung der Herausforderungen mit Unternehmensarchitekturmanagement (EAM)},
  shorttitle = {Datenschutzgrundverordnung (DSGVO)},
  journaltitle = {springerprofessional.de},
  url = {https://www.springerprofessional.de/datenschutzgrundverordnung-dsgvo-bewaeltigung-der-herausforderun/16059872},
  urldate = {2020-05-15},
  abstract = {Datenschutz nimmt eine zunehmend größere Bedeutung in der modernen Datenverarbeitung ein. Seit dem 25. Mai 2018 müssen Unternehmen der EU-Datenschutz-Grundverordnung (EU-DSGVO) entsprechen. Ziel ist die Vereinheitlichung der Datenschutzgesetze …},
  file = {C\:\\Users\\bollich_k\\Zotero\\storage\\QQT5CSPA\\16059872.html},
  langid = {german}
}

@inproceedings{davidekovaSoftwareApplicationLogging2016,
  title = {Software {{Application Logging}}: {{Aspects}} to {{Consider}} by {{Implementing Knowledge Management}}},
  shorttitle = {Software {{Application Logging}}},
  booktitle = {2016 2nd {{International Conference}} on {{Open}} and {{Big Data}} ({{OBD}})},
  author = {Dávideková, Monika and Gregu Ml, Michal},
  date = {2016-08},
  pages = {102--107},
  issn = {null},
  doi = {10.1109/OBD.2016.22},
  abstract = {Standard workday today includes use of software applications that enable faster task processing and can do so for several tasks in parallel for us. Still, also the best applications can stop working or may not work correctly. For investigating such unintended malfunctioning of a software application, logging is very important. By examining application logs, software developers can find the cause and provide an update or patch with fixed bugs. On the other hand, logging can provide enormous amount of data that can flood the memory. That is why it is important not to log everything. The decision about logging (how to do logging of what data) is done during the software development phase. This paper describes research that has been focused on logging strategies in form of case studies of software development projects and in conclusion we give some guidelines for future decisions on logging for software development teams that may lead to logging improvement.},
  eventtitle = {2016 2nd {{International Conference}} on {{Open}} and {{Big Data}} ({{OBD}})},
  file = {C\:\\Users\\bollich_k\\Zotero\\storage\\SMYWLQ4T\\7573696.html},
  keywords = {big data,C\# languages,Companies,Computers,data,decision making,Electronic mail,information,Java,knowledge,knowledge management,logging,project management,Software,software application logging,software development project,software engineering,software management}
}

@online{dynatraceApplicationPerformanceManagement,
  title = {Application Performance Management},
  author = {Dynatrace},
  journaltitle = {Dynatrace},
  url = {https://www.dynatrace.com/platform/application-performance-management/},
  urldate = {2020-05-26},
  abstract = {Learn about Dynatrace APM software that helps you easily boost performance and develop in depth application performance management solutions. Sign up now!},
  file = {C\:\\Users\\bollich_k\\Zotero\\storage\\7Z3WRCJ5\\application-performance-management.html},
  langid = {english}
}

@online{elasticELKStackElasticsearch,
  title = {ELK Stack: Elasticsearch, Logstash und Kibana | Elastic},
  shorttitle = {ELK Stack},
  author = {Elastic},
  url = {https://www.elastic.co/de/what-is/elk-stack},
  urldate = {2020-07-27},
  abstract = {Was ist der ELK Stack? Der ELK Stack ist eine Abkürzung für eine Kombination aus drei weit verbreiteten Open-Source-Projekten: E = Elasticsearch (auf der Basis von Lucene), L = Logstash und K = Kibana. Seitdem Beats hinzugekommen sind, wird der ELK Stack als Elastic Stack bezeichnet},
  file = {C\:\\Users\\bollich_k\\Zotero\\storage\\HEA8W85V\\elk-stack.html},
  langid = {german}
}

@inproceedings{fuWhereDevelopersLog2014,
  title = {Where Do Developers Log? An Empirical Study on Logging Practices in Industry},
  shorttitle = {Where Do Developers Log?},
  booktitle = {Companion {{Proceedings}} of the 36th {{International Conference}} on {{Software Engineering}}},
  author = {Fu, Qiang and Zhu, Jieming and Hu, Wenlu and Lou, Jian-Guang and Ding, Rui and Lin, Qingwei and Zhang, Dongmei and Xie, Tao},
  date = {2014-05-31},
  pages = {24--33},
  publisher = {{Association for Computing Machinery}},
  location = {{Hyderabad, India}},
  doi = {10.1145/2591062.2591175},
  url = {https://doi.org/10.1145/2591062.2591175},
  urldate = {2020-03-11},
  abstract = {System logs are widely used in various tasks of software system management. It is crucial to avoid logging too little or too much. To achieve so, developers need to make informed decisions on where to log and what to log in their logging practices during development. However, there exists no work on studying such logging practices in industry or helping developers make informed decisions. To fill this significant gap, in this paper, we systematically study the logging practices of developers in industry, with focus on where developers log. We obtain six valuable findings by conducting source code analysis on two large industrial systems (2.5M and 10.4M LOC, respectively) at Microsoft. We further validate these findings via a questionnaire survey with 54 experienced developers in Microsoft. In addition, our study demonstrates the high accuracy of up to 90\% F-Score in predicting where to log.},
  isbn = {978-1-4503-2768-8},
  keywords = {automatic logging,developer survey,Logging practice},
  series = {{{ICSE Companion}} 2014}
}

@online{googleAngularIntroductionAngular,
  title = {Angular - {{Introduction}} to the {{Angular Docs}}},
  author = {Google},
  url = {https://angular.io/docs},
  urldate = {2020-06-09},
  file = {C\:\\Users\\bollich_k\\Zotero\\storage\\NAPWA9LB\\docs.html}
}

@online{groteMicrosoftNETFramework,
  title = {Microsoft .NET Framework 4},
  author = {Grote, Matthias},
  url = {https://www.heise.de/download/product/.net-framework-18554},
  urldate = {2020-08-28},
  abstract = {Das .NET Framework 4 ist eine Laufzeitumgebung für Windows und unterstützt die Entwicklung von Windows-Apps.},
  langid = {german}
}

@inproceedings{heCharacterizingNaturalLanguage2018,
  title = {Characterizing the Natural Language Descriptions in Software Logging Statements},
  booktitle = {Proceedings of the 33rd {{ACM}}/{{IEEE International Conference}} on {{Automated Software Engineering}}},
  author = {He, Pinjia and Chen, Zhuangbin and He, Shilin and Lyu, Michael R.},
  date = {2018-09-03},
  pages = {178--189},
  publisher = {{Association for Computing Machinery}},
  location = {{Montpellier, France}},
  doi = {10.1145/3238147.3238193},
  url = {https://doi.org/10.1145/3238147.3238193},
  urldate = {2020-06-17},
  abstract = {Logging is a common programming practice of great importance in modern software development, because software logs have been widely used in various software maintenance tasks. To provide high-quality logs, developers need to design the description text in logging statements carefully. Inappropriate descriptions will slow down or even mislead the maintenance process, such as postmortem analysis. However, there is currently a lack of rigorous guide and specifications on developer logging behaviors, which makes the construction of description text in logging statements a challenging problem. To fill this significant gap, in this paper, we systematically study what developers log, with focus on the usage of natural language descriptions in logging statements. We obtain 6 valuable findings by conducting source code analysis on 10 Java projects and 7 C\# projects, which contain 28,532,975 LOC and 115,159 logging statements in total. Furthermore, our study demonstrates the potential of automated description text generation for logging statements by obtaining up to 49.04 BLEU-4 score and 62.1 ROUGE-L score using a simple information retrieval method. To facilitate future research in this field, the datasets have been publicly released.},
  file = {C\:\\Users\\bollich_k\\Zotero\\storage\\L2Z6D2MJ\\He et al. - 2018 - Characterizing the natural language descriptions i.pdf},
  isbn = {978-1-4503-5937-5},
  keywords = {empirical study,Logging,natural language processing},
  series = {{{ASE}} 2018}
}

@online{it-administrator.deClientServerArchitekturItadministrator,
  title = {Client-{{Server}}-{{Architektur}} | It-Administrator.De},
  author = {IT-Administrator.de},
  url = {https://www.it-administrator.de/lexikon/client-server-architektur.html},
  urldate = {2020-06-09},
  file = {C\:\\Users\\bollich_k\\Zotero\\storage\\NT83QYBV\\client-server-architektur.html}
}

@inproceedings{jayathilakeStructuredLogAnalysis2012,
  title = {Towards Structured Log Analysis},
  author = {Jayathilake, Dileepa},
  date = {2012-05-01},
  pages = {259--264},
  doi = {10.1109/JCSSE.2012.6261962},
  abstract = {Value of software log file analysis has been constantly increasing with the value of information to organizations. Log management tools still have a lot to deliver in order to empower their customers with the true strength of log information. In addition to the traditional uses such as testing software functional conformance, troubleshooting and performance benchmarking, log analysis has proven its capabilities in fields like intrusion detection and compliance evaluation. This is verified by the emphasis on log analysis in regulations like PCI DSS, FISMA, HIPAA and frameworks such as ISO 27001 and COBIT. In this paper we present an in depth analysis into current log analysis domains and common problems. A practical guide to the use of few popular log analysis tools is also included. Lack of proper support for structured analysis is identified as one major flaw in existing tools. After that, we describe a framework we developed for structured log analysis with the view of providing a solution to open problems in the domain. The core strength of the framework is its ability to handle many log file formats that are not well served by existing tools and providing sophisticated infrastructure for automating recurring log analysis procedures. We prove the usefulness of the framework with a simple experiment.},
  eventtitle = {{{JCSSE}} 2012 - 9th {{International Joint Conference}} on {{Computer Science}} and {{Software Engineering}}},
  isbn = {978-1-4673-1920-1}
}

@patent{justinDataLoggingDatabase2006,
  title = {Data Logging to a Database},
  author = {Justin, Antony},
  date = {2006-06-01},
  url = {https://patents.google.com/patent/US20060117091A1/en},
  urldate = {2020-04-28},
  file = {C\:\\Users\\bollich_k\\Zotero\\storage\\J5L6RLJ5\\Justin - 2006 - Data logging to a database.pdf},
  holder = {{Hewlett Packard Development Co LP}},
  keywords = {data,data processing,gathering,log,processing arrangement},
  number = {20060117091A1},
  type = {patentus}
}

@inproceedings{liDLFinderCharacterizingDetecting2019,
  title = {{{DLFinder}}: {{Characterizing}} and {{Detecting Duplicate Logging Code Smells}}},
  shorttitle = {{{DLFinder}}},
  booktitle = {2019 {{IEEE}}/{{ACM}} 41st {{International Conference}} on {{Software Engineering}} ({{ICSE}})},
  author = {Li, Zhenhao and Chen, Tse-Hsun and Yang, Jinqiu and Shang, Weiyi},
  date = {2019-05},
  pages = {152--163},
  issn = {1558-1225},
  doi = {10.1109/ICSE.2019.00032},
  abstract = {Developers rely on software logs for a wide variety of tasks, such as debugging, testing, program comprehension, verification, and performance analysis. Despite the importance of logs, prior studies show that there is no industrial standard on how to write logging statements. Recent research on logs often only considers the appropriateness of a log as an individual item (e.g., one single logging statement); while logs are typically analyzed in tandem. In this paper, we focus on studying duplicate logging statements, which are logging statements that have the same static text message. Such duplications in the text message are potential indications of logging code smells, which may affect developers' understanding of the dynamic view of the system. We manually studied over 3K duplicate logging statements and their surrounding code in four large-scale open source systems: Hadoop, CloudStack, ElasticSearch, and Cassandra. We uncovered five patterns of duplicate logging code smells. For each instance of the code smell, we further manually identify the problematic (i.e., require fixes) and justifiable (i.e., do not require fixes) cases. Then, we contact developers in order to verify our manual study result. We integrated our manual study result and developers' feedback into our automated static analysis tool, DLFinder, which automatically detects problematic duplicate logging code smells. We evaluated DLFinder on the four manually studied systems and two additional systems: Camel and Wicket. In total, combining the results of DLFinder and our manual analysis, we reported 82 problematic code smell instances to developers and all of them have been fixed.},
  eventtitle = {2019 {{IEEE}}/{{ACM}} 41st {{International Conference}} on {{Software Engineering}} ({{ICSE}})},
  file = {C\:\\Users\\bollich_k\\Zotero\\storage\\QULI5VFD\\8811945.html},
  keywords = {Cassandra,cloud computing,Cloud computing,CloudStack,code smell,data handling,Debugging,developers feedback,DLFinder,duplicate log,duplicate logging code smells,duplicate logging statements,dynamic view,ElasticSearch,empirical study,Hadoop,Java,log,Manuals,open source systems,parallel processing,problematic duplicate logging code,program debugging,program diagnostics,public domain software,Semantics,single logging statement,software logs,static analysis,Static analysis,static text message,Tools}
}

@book{liuPrinciplesApplicationsWell2017,
  title = {Principles and {{Applications}} of {{Well Logging}}},
  author = {Liu, Hongqi},
  date = {2017},
  edition = {2},
  publisher = {{Springer-Verlag}},
  location = {{Berlin Heidelberg}},
  doi = {10.1007/978-3-662-54977-3},
  url = {https://www.springer.com/de/book/9783662549766},
  urldate = {2020-04-01},
  abstract = {This book primarily focuses on the principles and applications of electric logging, sonic logging, nuclear logging, production logging and NMR logging, especially LWD tools, Sondex production logging tools and other advanced image logging techniques, such as ECLIPS 5700, EXCELL 2000 etc. that have been developed and used in the last two decades. Moreover, it examines the fundamentals of rock mechanics, which contribute to applications concerning the stability of borehole sidewall, safety density window of drilling fluid, fracturing etc. As such, the book offers a valuable resource for a wide range of readers, including students majoring in petrophysics, geophysics, geology and seismology, and engineers working in well logging and exploitation.},
  file = {C\:\\Users\\bollich_k\\Zotero\\storage\\PBCM3AFF\\9783662549766.html},
  isbn = {978-3-662-54976-6},
  langid = {english},
  series = {Springer {{Geophysics}}}
}

@article{liWhichLogLevel2016,
  title = {Which Log Level Should Developers Choose for a New Logging Statement?},
  author = {Li, Heng and Shang, Weiyi and Hassan, Ahmed E.},
  date = {2016-10-14},
  journaltitle = {Empirical Software Engineering},
  shortjournal = {Empirical Software Engineering},
  volume = {22},
  doi = {10.1007/s10664-016-9456-2},
  abstract = {Logging statements are used to record valuable runtime information about applications. Each logging statement is assigned a log level such that users can disable some verbose log messages while allowing the printing of other important ones. However, prior research finds that developers often have difficulties when determining the appropriate level for their logging statements. In this paper, we propose an approach to help developers determine the appropriate log level when they add a new logging statement. We analyze the development history of four open source projects (Hadoop, Directory Server, Hama, and Qpid), and leverage ordinal regression models to automatically suggest the most appropriate level for each newly-added logging statement. First, we find that our ordinal regression model can accurately suggest the levels of logging statements with an AUC (area under the curve; the higher the better) of 0.75 to 0.81 and a Brier score (the lower the better) of 0.44 to 0.66, which is better than randomly guessing the appropriate log level (with an AUC of 0.50 and a Brier score of 0.80 to 0.83) or naively guessing the log level based on the proportional distribution of each log level (with an AUC of 0.50 and a Brier score of 0.65 to 0.76). Second, we find that the characteristics of the containing block of a newly-added logging statement, the existing logging statements in the containing source code file, and the content of the newly-added logging statement play important roles in determining the appropriate log level for that logging statement.},
  file = {C\:\\Users\\bollich_k\\Zotero\\storage\\UA2DRX9U\\Li et al. - 2016 - Which log level should developers choose for a new.pdf}
}

@online{log4netLog4net,
  title = {Log4net 2.0.8},
  author = {Log4Net},
  url = {https://nuget.org/packages/log4net/},
  urldate = {2020-05-19},
  abstract = {log4net is a tool to help the programmer output log statements to a variety of output targets. In case of problems with an application, it is helpful to enable logging so that the problem can be located. With log4net it is possible to enable logging at runtime without modifying the application binary. The log4net package is designed so that log statements can remain in shipped code without incurring a high performance cost. It follows that the speed of logging (or rather not logging) is crucial. 

At the same time, log output can be so voluminous that it quickly becomes overwhelming. One of the distinctive features of log4net is the notion of hierarchical loggers. Using these loggers it is possible to selectively control which log statements are output at arbitrary granularity. 

log4net is designed with two distinct goals in mind: speed and flexibility},
  file = {C\:\\Users\\bollich_k\\Zotero\\storage\\JXQPX5WW\\log4net.html},
  langid = {english}
}

@online{LoggingLevelsWhat2017,
  title = {Logging {{Levels}}: {{What They Are}} and {{How They Help You}}},
  shorttitle = {Logging {{Levels}}},
  date = {2017-12-20T01:00:54+00:00},
  journaltitle = {Scalyr},
  url = {https://www.scalyr.com/blog/logging-levels/},
  urldate = {2020-04-22},
  abstract = {Today, we take a look at the idea of logging levels for entries in your logs. What are they, how do they work, and why should you use them?},
  langid = {american}
}

@online{luberWasIstElasticsearch2020,
  title = {Was ist Elasticsearch?},
  author = {Luber, Stefan},
  date = {2020-06-16},
  url = {https://www.bigdata-insider.de/was-ist-elasticsearch-a-939625/},
  urldate = {2020-07-27},
  abstract = {Elasticsearch ist eine Open-Source-Suchmaschine auf Basis von Apache Lucene. Sie arbeitet mit Indices, die aus JSON-Dokumenten im NoSQL-Format bestehen. Die Suchmaschine arbeitet sehr schnell, ist für die Suche in großen Datenmengen einsetzbar (Big Data) und unterstützt für eine hohe Verfügbarkeit verteilte Architekturen. Zusammen mit Kibana und Logstash bildet Elasticsearch den Elastic Stack.},
  file = {C\:\\Users\\bollich_k\\Zotero\\storage\\GLL8TALK\\was-ist-elasticsearch-a-939625.html},
  langid = {german}
}

@online{luberWasIstKibana,
  title = {Was ist Kibana?},
  author = {Luber, Stefan},
  url = {https://www.bigdata-insider.de/was-ist-kibana-a-912338/},
  urldate = {2020-07-27},
  abstract = {Kibana ist eine Open-Source-Analyse- und -Visualisierungsplattform. Sie bildet zusammen mit Elasticsearch und Logstash den Elastic-Stack und ermöglicht die Visualisierung der per Elasticsearch erhobenen Daten. Kibana beherrscht die klassischen Visualisierungsformen wie Histogramme, Liniendiagramme oder Kreisdiagramme und erlaubt die Darstellung von Zeitreihen oder geografischen Daten.},
  file = {C\:\\Users\\bollich_k\\Zotero\\storage\\X3CXGNWZ\\was-ist-kibana-a-912338.html},
  langid = {german}
}

@online{luberWasIstLogstash,
  title = {Was ist Logstash?},
  author = {Luber, Stefan},
  url = {https://www.bigdata-insider.de/was-ist-logstash-a-939698/},
  urldate = {2020-07-27},
  abstract = {Logstash ist eine Open-Source-basierte Software zur Erfassung, Verarbeitung, Transformation und Weiterleitung von Daten. Sie stellt Datenverarbeitungspipelines zur Verfügung und arbeitet mit Plug-ins und Filtern. Zusammen mit Elasticsearch und Kibana bildet Logstash den sogenannten Elastic Stack. Er lässt sich zur Analyse und Visualisierung großer Datenmengen verwenden.},
  file = {C\:\\Users\\bollich_k\\Zotero\\storage\\PDPMY46X\\was-ist-logstash-a-939698.html},
  langid = {german}
}

@book{martinRefactoringImprovingDesign2018,
  title = {Refactoring: {{Improving}} the {{Design}} of {{Existing Code}}},
  shorttitle = {Refactoring},
  author = {Martin, Fowler},
  date = {2018-11-20},
  edition = {2},
  publisher = {{Addison-Wesley Professional}},
  abstract = {"Whenever you read [Refactoring], it’s time to read it again. And if you haven’t read it yet, please do before writing another line of code."                –David Heinemeier Hansson,~Creator of Ruby on Rails, Founder \& CTO at Basecamp             Fully Revised and Updated—Includes New Refactorings and Code Examples     “Any fool can write code that a computer can understand. Good programmers write code that humans can understand.”  –M. Fowler (1999)  For more than twenty years, experienced programmers worldwide have relied on Martin Fowler’s Refactoring to improve the design of existing code and to enhance software maintainability, as well as to make existing code easier to understand.    This eagerly awaited new edition has been fully updated to reflect crucial changes in the programming landscape.  Refactoring, Second Edition,  features an updated catalog of refactorings and includes JavaScript code examples, as well as new functional examples that demonstrate refactoring without classes.    Like the original, this edition explains what refactoring is; why you should refactor; how to recognize code that needs refactoring; and how to actually do it successfully, no matter what language you use.  Understand the process and general principles of refactoring Quickly apply useful refactorings to make a program easier to comprehend and change Recognize “bad smells” in code that signal opportunities to refactor Explore the refactorings, each with explanations, motivation, mechanics, and simple examples Build solid tests for your refactorings Recognize tradeoffs and obstacles to refactoring   Includes free access to the canonical web edition, with even more refactoring resources. (See inside the book for details about how to access the web edition.)},
  langid = {english},
  pagetotal = {432}
}

@online{microsoftErsteSchritteBeim,
  title = {Erste Schritte beim Erstellen von einem Anbieter gehosteten SharePoint-Add-Ins},
  author = {Microsoft},
  url = {https://docs.microsoft.com/de-de/sharepoint/dev/sp-add-ins/get-started-creating-provider-hosted-sharepoint-add-ins},
  urldate = {2020-05-26},
  abstract = {Richten Sie eine Entwicklungsumgebung ein und erstellen Sie Ihr erstes, von einem Anbieter gehostetes SharePoint-Add-In.},
  file = {C\:\\Users\\bollich_k\\Zotero\\storage\\PJCYY3S4\\get-started-creating-provider-hosted-sharepoint-add-ins.html},
  langid = {german}
}

@online{microsoftWasIstSharePoint,
  title = {Was ist SharePoint?},
  author = {Microsoft},
  url = {https://support.office.com/de-de/article/was-ist-sharepoint-97b915e6-651b-43b2-827d-fb25777f446f},
  urldate = {2020-05-26},
  abstract = {Hier erfahren Sie, was SharePoint (in seinen verschiedenen Formen) ist und wo Sie weitere Informationen zu SharePoint finden.},
  file = {C\:\\Users\\bollich_k\\Zotero\\storage\\2WUIRAGN\\was-ist-sharepoint-97b915e6-651b-43b2-827d-fb25777f446f.html},
  langid = {german}
}

@online{microsoftWhatNETOpensource,
  title = {What Is .{{NET}}? {{An}} Open-Source Developer Platform.},
  shorttitle = {What Is .{{NET}}?},
  author = {Microsoft},
  journaltitle = {Microsoft},
  url = {https://dotnet.microsoft.com/learn/dotnet/what-is-dotnet},
  urldate = {2020-06-09},
  abstract = {.NET is a free, cross-platform, open-source developer platform. .NET has languages, editors, and libraries to build for web, mobile, desktop, gaming, and IoT.},
  file = {C\:\\Users\\bollich_k\\Zotero\\storage\\HXKLMHZ7\\what-is-dotnet.html},
  langid = {english}
}

@online{MonitoringMaintainingSharePoint,
  title = {Monitoring and {{Maintaining}} a {{SharePoint}} 2016 {{Deployment}} | {{SpringerLink}}},
  url = {https://link.springer.com/chapter/10.1007/978-1-4842-1999-7_18},
  urldate = {2020-03-11},
  file = {C\:\\Users\\bollich_k\\Zotero\\storage\\4HSHNREP\\978-1-4842-1999-7_18.html}
}

@online{MoreGoodTips,
  title = {7 {{More Good Tips}} on {{Logging}} | Svese {{Engineering Blog}}},
  url = {https://svese.dev/7-more-good-tips-on-logging/},
  urldate = {2020-07-14},
  file = {C\:\\Users\\bollich_k\\Zotero\\storage\\XNQEH8I3\\7-more-good-tips-on-logging.html},
  langid = {american}
}

@online{nlogNLog,
  title = {{{NLog}} 4.7.2},
  author = {NLog},
  url = {https://nuget.org/packages/NLog/},
  urldate = {2020-05-19},
  abstract = {NLog is a logging platform for .NET with rich log routing and management capabilities.
NLog supports traditional logging, structured logging and the combination of both.

Supported platforms:

- .NET Framework 3.5, 4, 4.5, 4.6, 4.7 \& 4.8
- .NET Standard 1.3+ and 2.0+;
- .NET Framework 4 client profile
- Xamarin Android, Xamarin iOs
- UWP
- Windows Phone 8
- Silverlight 4 and 5
- Mono 4

For ASP.NET Core, check: https://www.nuget.org/packages/NLog.Web.AspNetCore},
  file = {C\:\\Users\\bollich_k\\Zotero\\storage\\H2MGSCUM\\NLog.html},
  langid = {english}
}

@online{NLogVsLog4net2018,
  title = {{{NLog}} vs Log4net vs {{Serilog}}: {{Compare}} .{{NET Logging Frameworks}}},
  shorttitle = {{{NLog}} vs Log4net vs {{Serilog}}},
  date = {2018-08-27T13:12:37+00:00},
  journaltitle = {Stackify},
  url = {https://stackify.com/nlog-vs-log4net-vs-serilog/},
  urldate = {2020-05-19},
  abstract = {Compare three of the most popular logging frameworks in the .NET space: log4net, NLog, and Serilog. Understand each frameworks' pros and cons.},
  file = {C\:\\Users\\bollich_k\\Zotero\\storage\\AMRI723I\\nlog-vs-log4net-vs-serilog.html},
  langid = {american}
}

@online{objectrocketWhatAreElasticsearch,
  title = {What Are {{Elasticsearch Beats}}?},
  author = {ObjectRocket},
  journaltitle = {ObjectRocket},
  url = {https://www.objectrocket.com/resource/what-are-elasticsearch-beats/},
  urldate = {2020-08-03},
  abstract = {Find out how the Elastic Stack and Beats provide one of the most efficient data collection and indexing frameworks in Elasticsearch.},
  file = {C\:\\Users\\bollich_k\\Zotero\\storage\\LWF2V9GI\\what-are-elasticsearch-beats.html},
  langid = {american}
}

@online{OptimalLogging,
  title = {Optimal {{Logging}}},
  journaltitle = {Google Testing Blog},
  url = {https://testing.googleblog.com/2013/06/optimal-logging.html},
  urldate = {2020-03-31},
  abstract = {by Anthony Vallone   How long does it take to find the root cause of a failure in your system? Five minutes? Five days? If you answered clos...},
  file = {C\:\\Users\\bollich_k\\Zotero\\storage\\8G529BRA\\optimal-logging.html},
  langid = {english}
}

@online{packof7SharePointDrivenApplication,
  title = {SharePoint Driven Application – Pack of 7},
  author = {Pack of 7},
  url = {https://packof7.com/sharepoint-driven-application/},
  urldate = {2020-08-21},
  file = {C\:\\Users\\bollich_k\\Zotero\\storage\\82UXVGYY\\sharepoint-driven-application.html},
  langid = {german}
}

@online{PDFNovelApproach,
  title = {({{PDF}}) {{A}} Novel Approach for a File-System Integrity Monitor Tool of {{Xen}} Virtual Machine},
  url = {https://www.researchgate.net/publication/221609764_A_novel_approach_for_a_file-system_integrity_monitor_tool_of_Xen_virtual_machine},
  urldate = {2020-04-28}
}

@inproceedings{pecchiaIndustryPracticesEvent2015,
  title = {Industry {{Practices}} and {{Event Logging}}: {{Assessment}} of a {{Critical Software Development Process}}},
  shorttitle = {Industry {{Practices}} and {{Event Logging}}},
  author = {Pecchia, Antonio and Cinque, Marcello and Carrozza, Gabriella and Cotroneo, Domenico},
  date = {2015-05-01},
  pages = {169--178},
  doi = {10.1109/ICSE.2015.145},
  file = {C\:\\Users\\bollich_k\\Zotero\\storage\\YUDA9BT4\\Pecchia et al. - 2015 - Industry Practices and Event Logging Assessment o.pdf}
}

@online{RheinwerkComputingJava,
  title = {Rheinwerk {{Computing}} :: {{Java}} 7 - {{Mehr}} Als Eine {{Insel}} - 20 {{Logging}} Und {{Monitoring}}},
  url = {http://openbook.rheinwerk-verlag.de/java7/1507_20_001.html},
  urldate = {2020-04-02},
  file = {C\:\\Users\\bollich_k\\Zotero\\storage\\RQPV93NG\\1507_20_001.html}
}

@online{RheinwerkComputingJavaa,
  title = {Rheinwerk {{Computing}} :: {{Java SE}} 8 {{Standard}}-{{Bibliothek}} - {{Logging}} Und {{Monitoring}}},
  url = {http://openbook.rheinwerk-verlag.de/java8/19_001.html},
  urldate = {2020-04-02},
  file = {C\:\\Users\\bollich_k\\Zotero\\storage\\ZVXIMBRQ\\19_001.html}
}

@legislation{RichtlinieEU20162016,
  title = {Richtlinie (EU) 2016/680 des Europäischen Parlaments und des Rates vom 27. April 2016 zum Schutz natürlicher Personen bei der Verarbeitung personenbezogener Daten durch die zuständigen Behörden zum Zwecke der Verhütung, Ermittlung, Aufdeckung oder Verfolgung von Straftaten oder der Strafvollstreckung sowie zum freien Datenverkehr und zur Aufhebung des Rahmenbeschlusses 2008/977/JI des Rates},
  date = {2016-05-04},
  journaltitle = {119},
  volume = {OJ L},
  url = {http://data.europa.eu/eli/dir/2016/680/oj/deu},
  urldate = {2020-05-13},
  langid = {german},
  number = {32016L0680}
}

@inproceedings{rongHowLoggingPractice2018,
  title = {How {{Is Logging Practice Implemented}} in {{Open Source Software Projects}}? {{A Preliminary Exploration}}},
  shorttitle = {How {{Is Logging Practice Implemented}} in {{Open Source Software Projects}}?},
  booktitle = {2018 25th {{Australasian Software Engineering Conference}} ({{ASWEC}})},
  author = {Rong, Guoping and Gu, Shenghui and Zhang, He and Shao, Dong and Liu, Wanggen},
  date = {2018-11},
  pages = {171--180},
  issn = {2377-5408},
  doi = {10.1109/ASWEC.2018.00031},
  abstract = {Background: Logs are the footprints that software systems produce during runtime, which can be used to understand the dynamic behavior of these software systems. To generate logs, logging practice is accepted by developers to place logging statements in the source code of software systems. Compared to the great number of studies on log analysis, the research on logging practice is relatively scarce, which raises a very critical question, i.e. as the original intention, can current logging practice support capturing the behavior of software systems effectively? Aims: To answer this question, we first need to understand how logging practices are implemented these software projects. Method: In this paper, we carried out an empirical study to explore the logging practice in open source software projects so as to establish a basic understanding on how logging practice is applied in real world software projects. The density, log level (what to log?) and context (where to log?) are measured for our study. Results: Based on the evidence we collected in 28 top open source projects, we find the logging practice is adopted highly inconsistently among different developers both across projects and even within one project in terms of the density and log levels of logging statements. However, the choice of what context the logging statements to place is consistent to a fair degree. Conclusion: Both the inconsistency in density and log level and the convergence of context have forced us to question whether it is a reliable means to understand the runtime behavior of software systems via analyzing the logs produced by the current logging practice.},
  eventtitle = {2018 25th {{Australasian Software Engineering Conference}} ({{ASWEC}})},
  file = {C\:\\Users\\bollich_k\\Zotero\\storage\\XYBDKPJ8\\8587302.html},
  keywords = {log analysis,log; logging practice; empirical study; Java-based,logging practice support,logging statements,Measurement,open source software projects,public domain software,Reliability,Runtime,software engineering,software systems,Software systems,system monitoring,Tools}
}

@inproceedings{rongSystematicReviewLogging2017,
  title = {A {{Systematic Review}} of {{Logging Practice}} in {{Software Engineering}}},
  booktitle = {2017 24th {{Asia}}-{{Pacific Software Engineering Conference}} ({{APSEC}})},
  author = {Rong, Guoping and Zhang, Qiuping and Liu, Xinbei and Gu, Shenghiu},
  date = {2017-12},
  pages = {534--539},
  issn = {null},
  doi = {10.1109/APSEC.2017.61},
  abstract = {Background: Logging practice is a critical activity in software development, which aims to offer significant information to understand the runtime behavior of software systems and support better software maintenance. There have been many relevant studies dedicated to logging practice in software engineering recently, yet it lacks a systematic understanding to the adoption state of logging practice in industry and research progress in academia. Objective: This study aims to synthesize relevant studies on the logging practice and portray a big picture of logging practice in software engineering so as to understand current adoption status and identify research opportunities. Method: We carried out a systematic review on the relevant studies on logging practice in software engineering. Results: Our study identified 41 primary studies relevant to logging practice. Typical findings are: (1) Logging practice attracts broad interests among researchers in many concrete research areas. (2) Logging practice occurred in many development types, among which the development of fault tolerance systems is the most adopted type. (3) Many challenges exist in current logging practice in software engineering, e.g., tradeoff between logging overhead and analysis cost, where and what to log, balance between enough logging and system performance, etc. Conclusion: Results show that logging practice plays a vital role in various applications for diverse purposes. However, there are many challenges and problems to be solved. Therefore, various novel techniques are necessary to guide developers conducting logging practice and improve the performance and efficiency of logging practice.},
  eventtitle = {2017 24th {{Asia}}-{{Pacific Software Engineering Conference}} ({{APSEC}})},
  file = {C\:\\Users\\bollich_k\\Zotero\\storage\\75AXDN39\\8305977.html},
  keywords = {Fault tolerance,fault tolerance systems,Fault tolerant systems,logging practice,Logging Practice,runtime behavior,software development,software engineering,Software engineering,Software Engineering,software maintenance,software systems,Software systems,system monitoring,system performance,Systematic Literature Review,Systematics,Tools}
}

@book{selkeLifeloggingDigitaleSelbstvermessung2016,
  title = {Lifelogging: Digitale Selbstvermessung und Lebensprotokollierung zwischen disruptiver Technologie und kulturellem Wandel},
  shorttitle = {Lifelogging},
  editor = {Selke, Stefan},
  date = {2016},
  publisher = {{VS Verlag für Sozialwissenschaften}},
  doi = {10.1007/978-3-658-10416-0},
  url = {https://www.springer.com/de/book/9783658104153},
  urldate = {2020-04-07},
  abstract = {Der vorliegende Band liefert fundierte Analysen zur theoretischen Einordnung eines aktuellen gesellschaftlichen Phänomens zwischen innovativen, wertverändernden und zugleich disruptiven Technologien sowie dem gesellschaftlichen und kulturellen Wandel. Lifelogging, die digitale Selbstvermessung und Lebensprotokollierung des Menschen, findet sich als gesellschaftlich relevantes Thema heutzutage nicht nur in Forschung und Wissenschaft sondern auch in der Literatur, dem Feuilleton oder im Theater wieder. Das Spektrum von Lifelogging reicht vom Sleep- und Mood- über Sex- und Work- bis hin zu Thing- und Deathlogging. Dabei tauchen zahlreiche Fragen auf: Wie lebt es sich in der Gesellschaft von Daten? Ist der vermessene Mensch automatisch auch der verbesserte Mensch? Und wenn ja, welchen Preis zahlt er dafür? Entstehen durch Lifelogging neue Wirklichkeitskategorien oder ein neues Ordnungsprinzip des Sozialen? Wie verändert sich der „soziale Blick“? Die AutorInnen des Sammelbandes geben detaillierte Antworten auf diese drängenden Fragen.},
  file = {C\:\\Users\\bollich_k\\Zotero\\storage\\UWQB8QW6\\9783658104153.html},
  isbn = {978-3-658-10415-3},
  langid = {german}
}

@article{shangStudyingRelationshipLogging2015,
  title = {Studying the Relationship between Logging Characteristics and the Code Quality of Platform Software},
  author = {Shang, Weiyi and Nagappan, Meiyappan and Hassan, Ahmed E.},
  date = {2015-02-01},
  journaltitle = {Empirical Software Engineering},
  shortjournal = {Empir Software Eng},
  volume = {20},
  pages = {1--27},
  issn = {1573-7616},
  doi = {10.1007/s10664-013-9274-8},
  url = {https://doi.org/10.1007/s10664-013-9274-8},
  urldate = {2020-06-16},
  abstract = {Platform software plays an important role in speeding up the development of large scale applications. Such platforms provide functionalities and abstraction on which applications can be rapidly developed and easily deployed. Hadoop and JBoss are examples of popular open source platform software. Such platform software generate logs to assist operators in monitoring the applications that run on them. These logs capture the doubts, concerns, and needs of developers and operators of platform software. We believe that such logs can be used to better understand code quality. However, logging characteristics and their relation to quality has never been explored. In this paper, we sought to empirically study this relation through a case study on four releases of Hadoop and JBoss. Our findings show that files with logging statements have higher post-release defect densities than those without logging statements in 7 out of 8 studied releases. Inspired by prior studies on code quality, we defined log-related product metrics, such as the number of log lines in a file, and log-related process metrics such as the number of changed log lines. We find that the correlations between our log-related metrics and post-release defects are as strong as their correlations with traditional process metrics, such as the number of pre-release defects, which is known to be one the metrics with the strongest correlation with post-release defects. We also find that log-related metrics can complement traditional product and process metrics resulting in up to 40~\% improvement in explanatory power of defect proneness. Our results show that logging characteristics provide strong indicators of defect-prone source code files. However, we note that removing logs is not the answer to better code quality. Instead, our results show that it might be the case that developers often relay their concerns about a piece of code through logs. Hence, code quality improvement efforts (e.g., testing and inspection) should focus more on the source code files with large amounts of logs or with large amounts of log churn.},
  langid = {english},
  number = {1}
}

@inproceedings{shangUnderstandingLogLines2014,
  title = {Understanding {{Log Lines Using Development Knowledge}}},
  booktitle = {2014 {{IEEE International Conference}} on {{Software Maintenance}} and {{Evolution}}},
  author = {Shang, Weiyi and Nagappan, Meiyappan and Hassan, Ahmed E. and Jiang, Zhen Ming},
  date = {2014-09},
  pages = {21--30},
  issn = {1063-6773},
  doi = {10.1109/ICSME.2014.24},
  abstract = {Logs are generated by output statements that developers insert into the code. By recording the system behaviour during runtime, logs play an important role in the maintenance of large software systems. The rich nature of logs has introduced a new market of log management applications (e.g., Splunk, XpoLog and log stash) that assist in storing, querying and analyzing logs. Moreover, recent research has demonstrated the importance of logs in operating, understanding and improving software systems. Thus log maintenance is an important task for the developers. However, all too often practitioners (i.e., operators and administrators) are left without any support to help them unravel the meaning and impact of specific log lines. By spending over 100 human hours and manually examining all the email threads in the mailing list for three open source systems (Hadoop, Cassandra and Zookeeper) and performing web search on sampled logging statements, we found 15 email inquiries and 73 inquiries from web search about different log lines. We identified that five types of development knowledge that are often sought from the logs by practitioners: meaning, cause, context, impact and solution. Due to the frequency and nature of log lines about which real customers inquire, documenting all the log lines or identifying which ones to document is not efficient. Hence in this paper we propose an on-demand approach, which associates the development knowledge present in various development repositories (e.g., code commits and issues reports) with the log lines. Our case studies show that the derived development knowledge can be used to resolve real-life inquiries about logs.},
  eventtitle = {2014 {{IEEE International Conference}} on {{Software Maintenance}} and {{Evolution}}},
  file = {C\:\\Users\\bollich_k\\Zotero\\storage\\YYAKDWTL\\6976068.html},
  keywords = {Context,development knowledge,Electronic mail,Engines,Google,Internet,Knowledge engineering,log lines,log maintenance,open source systems,Program understanding,public domain software,Software Logs,software maintenance,Software maintenance,Software systems,system monitoring,Web search}
}

@online{swerskyLoggingBestPractices2018,
  title = {C\# {{Logging}} Best Practices in 2019 with Examples and Tools},
  author = {Swersky, Dave},
  date = {2018-12-06},
  journaltitle = {Raygun Blog},
  url = {https://raygun.com/blog/c-sharp-logging-best-practices/},
  urldate = {2020-05-15},
  abstract = {What are the best practices for error logging in C\#? We explore best practices with examples and tools},
  file = {C\:\\Users\\bollich_k\\Zotero\\storage\\YC6MLIJR\\c-sharp-logging-best-practices.html},
  langid = {english}
}

@online{timmsNLogVsLog4net2018,
  title = {{{NLog}} vs. Log4net vs. {{Serilog}} - {{DZone Integration}}},
  author = {Timms, Simon},
  date = {2018-08-31},
  journaltitle = {dzone.com},
  url = {https://dzone.com/articles/nlog-vs-log4net-vs-serilog-comparing-net-logging-f},
  urldate = {2020-05-19},
  abstract = {This article takes a look at three popular logging frameworks — NLog, log4net, and Serilog — and compares each of them and explores which one is the best.},
  file = {C\:\\Users\\bollich_k\\Zotero\\storage\\87NNHPLI\\nlog-vs-log4net-vs-serilog-comparing-net-logging-f.html},
  langid = {english}
}

@article{vainioImplementationCentralizedLogging2018,
  title = {Implementation of {{Centralized Logging}} and {{Log Analysis}} in {{Cloud Transition}}},
  author = {Vainio, Antti},
  date = {2018-08-20},
  url = {https://aaltodoc.aalto.fi:443/handle/123456789/33743},
  urldate = {2020-04-28},
  abstract = {Centralized logging can be used to collect log data from multiple log files on multiple separate server machines and transmit the data to a single centralized location. Log analysis on top of that can automatically process large amounts of logs for various different purposes including problem detection, troubleshooting, monitoring system performance, identifying security incidents, and understanding user behavior. As the volume of log data is growing when software systems, networks, and services grow in size, the log data located on multiple separate server machines can be difficult to manage. The traditional way of manually inspecting logs has also become too labor-intensive and error-prone when large amounts of log data need to be analyzed. Setting up centralized logging and automatic log analysis systems can be used to solve this problem. 
 
This thesis explains the concepts of log data, centralized logging, and log analysis, and also takes a look at existing software solutions to implement such a system. The solutions covered in this thesis are ones that are available for download and installation, in order to have more control over the implementation and to allow isolating the centralized logging system inside a local network. A case study is also conducted, where centralized logging and log analysis is implemented for an existing system using some of the software solutions studied in this thesis. The case study focuses on challenges that arise as the case study system is going through cloud transition and when the analyzed log data is mostly unstructured and difficult to automatically parse. 
 
The thesis presents the benefits that the complete centralized logging and log analysis setup has brought for the original system. Additional findings about the implementation process and the finished system are also discussed. While the final setup works well and did not require changes in the original system itself, there are still some aspects that are beneficial to consider when developing a logging system for new software.},
  file = {C\:\\Users\\bollich_k\\Zotero\\storage\\KF2Y4BI5\\Vainio - 2018 - Implementation of Centralized Logging and Log Anal.pdf;C\:\\Users\\bollich_k\\Zotero\\storage\\GIPE7JNR\\33743.html},
  langid = {english}
}

@online{WhatDataLogging,
  title = {What Is {{Data Logging}}? - {{Definition}} from {{Techopedia}}},
  shorttitle = {What Is {{Data Logging}}?},
  journaltitle = {Techopedia.com},
  url = {https://www.techopedia.com/definition/596/data-logging},
  urldate = {2020-03-31},
  abstract = {Data Logging Definition - Data logging is the process of collecting and storing data over},
  file = {C\:\\Users\\bollich_k\\Zotero\\storage\\IXWLSE53\\data-logging.html},
  langid = {english}
}

@article{yuanBeConservativeEnhancing,
  title = {Be {{Conservative}}: {{Enhancing Failure Diagnosis}} with {{Proactive Logging}}},
  author = {Yuan, Ding and Park, Soyeon and Huang, Peng and Liu, Yang and Lee, Michael M and Tang, Xiaoming and Zhou, Yuanyuan and Savage, Stefan},
  pages = {14},
  abstract = {When systems fail in the field, logged error or warning messages are frequently the only evidence available for assessing and diagnosing the underlying cause. Consequently, the efficacy of such logging—how often and how well error causes can be determined via postmortem log messages—is a matter of significant practical importance. However, there is little empirical data about how well existing logging practices work and how they can yet be improved. We describe a comprehensive study characterizing the efficacy of logging practices across five large and widely used software systems. Across 250 randomly sampled reported failures, we first identify that more than half of the failures could not be diagnosed well using existing log data. Surprisingly, we find that majority of these unreported failures are manifested via a common set of generic error patterns (e.g., system call return errors) that, if logged, can significantly ease the diagnosis of these unreported failure cases. We further mechanize this knowledge in a tool called Errlog, that proactively adds appropriate logging statements into source code while adding only 1.4\% performance overhead. A controlled user study suggests that Errlog can reduce diagnosis time by 60.7\%.},
  file = {C\:\\Users\\bollich_k\\Zotero\\storage\\I6NMWTFS\\Yuan et al. - Be Conservative Enhancing Failure Diagnosis with .pdf},
  langid = {english}
}

@inproceedings{yuanImprovingSoftwareDiagnosability2011,
  title = {Improving Software Diagnosability via Log Enhancement},
  booktitle = {Proceedings of the Sixteenth International Conference on {{Architectural}} Support for Programming Languages and Operating Systems},
  author = {Yuan, Ding and Zheng, Jing and Park, Soyeon and Zhou, Yuanyuan and Savage, Stefan},
  date = {2011-03-05},
  pages = {3--14},
  publisher = {{Association for Computing Machinery}},
  location = {{Newport Beach, California, USA}},
  doi = {10.1145/1950365.1950369},
  url = {https://doi.org/10.1145/1950365.1950369},
  urldate = {2020-06-17},
  abstract = {Diagnosing software failures in the field is notoriously difficult, in part due to the fundamental complexity of trouble-shooting any complex software system, but further exacerbated by the paucity of information that is typically available in the production setting. Indeed, for reasons of both overhead and privacy, it is common that only the run-time log generated by a system (e.g., syslog) can be shared with the developers. Unfortunately, the ad-hoc nature of such reports are frequently insufficient for detailed failure diagnosis. This paper seeks to improve this situation within the rubric of existing practice. We describe a tool, LogEnhancer that automatically "enhances" existing logging code to aid in future post-failure debugging. We evaluate LogEnhancer on eight large, real-world applications and demonstrate that it can dramatically reduce the set of potential root failure causes that must be considered during diagnosis while imposing negligible overheads.},
  file = {C\:\\Users\\bollich_k\\Zotero\\storage\\ZVWGMEG8\\Yuan et al. - 2011 - Improving software diagnosability via log enhancem.pdf},
  isbn = {978-1-4503-0266-1},
  keywords = {log,software diagnosability,static analysis},
  series = {{{ASPLOS XVI}}}
}

@article{yuanSherLogErrorDiagnosis2010,
  title = {{{SherLog}}: Error Diagnosis by Connecting Clues from Run-Time Logs},
  shorttitle = {{{SherLog}}},
  author = {Yuan, Ding and Mai, Haohui and Xiong, Weiwei and Tan, Lin and Zhou, Yuanyuan and Pasupathy, Shankar},
  date = {2010-03-05},
  journaltitle = {ACM SIGPLAN Notices},
  shortjournal = {ACM SIGPLAN Notices},
  volume = {45},
  pages = {143},
  doi = {10.1145/1735971.1736038}
}


