\chapter{Einrichtung des zentralisierten Logging-Servers}

Die im vorherigen Kapitel durchgeführte Evaluation kam zum Entschluss, dass der Elastic Stack die Anforderungen des CFT Portale am besten erfüllen kann. 
Daher wird in diesem Kapitel ein zentralisierter Logging-Server mit dem Elastic Stack installiert und konfiguriert.
Dafür wird zu Beginn ein Server benötigt, auf dem die einzelnen Komponenten installiert werden können. 
Anschließend müssen die einzelnen Tools des Elastic Stacks installiert und konfiguriert werden. \\
Dieses Kapitel ist wie folgt aufgebaut: 
\begin{itemize}
    \item RedHat Server 
    \item Elasticsearch
    \item Kibana
    \item Logstash
    \item Filebeat
\end{itemize}


\section{RedHat Server}

Damit die einzelnen Komponenten des Elastic Stack installiert werden können, musste ein Server beantragt werden. 
Dafür wurde ein Auftrag an das CFT Infrastruktur der KVWL gesendet, um so einen virtuellen Server zu erhalten. 
Wie schon in Kapitel \ref{kap:bewertungTools} geschrieben wurde, werden im CFT Portale auch Linux-Server verwendet. 
In der Regel werden RedHat Server genutzt. 
So ist es auch bei dem Server für das zentralisierte Logging. 
Es ist ein RedHat Server mit der Version 7.9. \\
Damit die Kommunikation zum Server erfolgen kann, müssen einige Ports auf dem Server freigeschaltet werden. 
Elasticsearch und Kibana nutzen die Ports 9200 und 5601.
Ohne Freischalten der Ports würde die Kommunikation von anderen Systemen nicht funktionieren. 
Die Portfreischaltung erfolgte mit diesen Befehlen: 
\begin{lstlisting} [language=bash]
$ sudo firewall-cmd --zone=public --add-port=9200/tcp --permanent    
$ sudo firewall-cmd --zone=public --add-port=5601/tcp --permanent    
\end{lstlisting}

Bevor die Installation der Elastic Stack Komponenten erfolgen konnte, musste festgelegt werden wie die Installation durchgeführt werden soll. 
Denn die KVWL nutzt \textit{Satellite} um die installierten Packages zu verwalten. 
Aktuell sind die Komponenten des Elastic Stack nicht im Satellite eingebunden. 
Daher musste geklärt werden, wie die Komponenten installiert werden dürfen. 
Um den organisatorischen Aufwand möglichst gering zu halten, wurde in Absprache mit den Administratoren festgelegt, dass eine manuelle Installation derzeit durchgeführt werden soll. 
Im Anschluss an diese Bachelorarbeit sollen die Pakete, sofern das Ergebnis zufriedenstellend ist, ins \textit{Satellite} eingebunden werden, um den zukünftigen Wartungsaufwand gering zu halten. 

\section{Elasticsearch}

Die erste zu installierende Komponente des Elastic Stack ist Elasticsearch.
Bei der Installation wurde auf die Anleitung vom Hersteller zurückgegriffen. \cite{elasticInstallElasticsearchRPM}
Bei der Installation war es wichtig zu beachten, die richtigen Packages runterzuladen. 
Sollte die Open-Source-Version runtergeladen und installiert worden sein, dann ist es nicht möglich ein Upgrade auf die Basic-Version zu vollbringen. 
Damit anschließend die Basic Version genutzt werden kann, muss der komplette Stack neu installiert werden. 
Daher musste darauf geachtet werden, dass die Basic Version direkt installiert wird. \\
Aus Sicherheitsgründen hat der Server keinen Zugriff auf das Internet. 
Daher müssen die Installationspakete manuell vom Entwickler-Rechner runtergeladen werden und anschließend zum Server kopiert werden. 
Da es sich um einen RedHat Server handelt, werden \textit{rpm-Pakete} runtergeladen und installiert.
Der Befehl der genutzt wurde, um das Package runterzuladen, ist: 
\begin{lstlisting}[language=bash]
wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.10.0-x86_64.rpm
\end{lstlisting}
Nachdem der Download fertiggestellt wurde, musste das \textit{rpm} package auf den RedHat Server kopiert werden:
\begin{lstlisting} [language=bash]
pscp -P 22 elasticsearch-7.10.0-x86_64.rpm <user>@<server>:<path>
\end{lstlisting}
Anschließend erfolgte die Installation des \textit{rpm} Pakets.
Nach der Installation wurde eingestellt, dass der Elasticsearch Service automatisch beim Hochfahren des Servers startet.

\begin{lstlisting} [language=bash]
sudo rpm --install elasticsearch-7.10.0-x86_64.rpm
sudo /bin/systemctl daemon-reload 
sudo /bin/systemctl enable elasticsearch.service
\end{lstlisting}

Nun kann der Service gestartet werden. 
Zum Starten und Stoppen werden folgende Befehle genutzt: 
\begin{lstlisting}[language=bash]
sudo systemctl start elasticsearch.service
sudo systemctl stop elasticsearch.service    
\end{lstlisting}
Um zu überprüfen ob der Elasticsearch-Service erfolgreich gestartet ist, kann der Befehl genutzt werden: 
\begin{lstlisting}[language=bash]
curl localhost:9200
\end{lstlisting}
Die zu erwartende Ausgabe sieht wie folgt aus: 
\begin{lstlisting}[language=bash]
{
"name" : "<server-name>",
"cluster_name" : "elasticsearch",
"cluster_uuid" : "5unW2cLtQoumj2z7P75pBA",
"version" : {
"number" : "7.10.0",
"build_flavor" : "default",
"build_type" : "rpm",
"build_hash" : "51e9d6f22758d0374a0f3f5c6e8f3a7997850f96",
"build_date" : "2020-11-09T21:30:33.964949Z",
"build_snapshot" : false,
"lucene_version" : "8.7.0",
"minimum_wire_compatibility_version" : "6.8.0",
"minimum_index_compatibility_version" : "6.0.0-beta1"
},
"tagline" : "You Know, for Search"
}
\end{lstlisting}
Hiermit ist die Installation abgeschlossen. 
Damit der Elasticsearch-Service von außerhalb erreicht werden kann, muss der Service entsprechend konfiguriert werden. 
Dafür müssen die IP-Adressen der Server eingetragen werden, die Daten an Elasticsearch senden dürfen. 
Nach Installation ist es erstmal nur erlaubt, Daten von localhost zu senden. 
Die Konfiguration muss in der \textit{elasticsearch.yml} Datei eingetragen werden.
Diese ist im Pfad \glqq \textit{/etc/elasticsearch/elasticsearch.yml}\grqq{} zu finden.
Für den Testfall ist es möglich zu definieren, dass von überall Daten an Elasticsearch gesendet werden können. 
Dafür muss die IP-Adresse \textit{0.0.0.0} eingetragen werden. 
Das Eintragen der IP-Adressen muss in \textit{network.host} eingetragen werden.
Wenn mehrere IP-Adressen benötigt werden, dann erfolgen die Einträge in \textit{network.hosts}. 
Elasticsearch ist mit diesen Konfigurationen nun bereit, Daten zu erhalten.

\section{Kibana}

Die nächste zu installierende Komponente ist Kibana. 
Wie bei der Installation von Elasticsearch wird hier auch auf die Anleitung des Herstellers zugegriffen, um die Installation erfolgreich durchzuführen. \cite{elasticInstallKibanaRPM}
Die Installation des \textit{rpm-Paketes} von Kibana erfolgt auf vergleichbare Weise wie die Installation des Packages von Elasticsearch. 
Daher werden die einzelnen Schritte nicht noch einmal vorgeführt. \\

\subsection{Index Pattern}
Kibana ist im Vergleich zu Elasticsearch eine Webanwendung, die mit einem Internet Browser erreicht werden kann und von Nutzern in Zukunft genutzt wird. 
Daher müssen wichtige Bestandteile der Oberfläche von Kibana näher erläutert werden. \\
Es müssen \textit{index patterns} erstellt werden, um die Logs aus dem Elasticsearch visualisieren zu können.
\textit{Index pattern} sind Muster, nach denen in den Logs gesucht wird. 
Das Suchen erfolgt dabei auf ein bestimmtes Attribut der Logs, dem \textit{index}.
Ein Beispiel für ein \textit{index pattern} ist \textit{\glqq prod-*\grqq{}}.
Jedes Log mit dem Präfix \textit{prod} wird angezeigt. \\
Doch bevor ein \textit{index pattern} erstellt werden kann, müssen Daten im Elasticsearch vorhanden sein. 
Das hat den Vorteil, dass keine \textit{Index Pattern} erstellt werden können, die niemals genutzt werden können, weil keine Daten zu dem Pattern passen.
Wenn Daten vorhanden sind, können im Reiter \textit{Stack Management -> Index Patterns} Index Patterns verwaltet werden.  
Dabei muss ein \textit{Index Pattern} als default definiert werden. 
Das als default definierte \textit{index pattern} wird beim Aufrufen von Kibana angezeigt. 
Die Logs, die hinter diesem Pattern stehen, werden in \textit{Discover} angezeigt.  \cite{elasticCreateIndexPattern}

\subsection{Dashboards}
Die Oberfläche von Kibana ermöglicht es, individuell angepasste Dashboards zu erstellen. 
Dabei können mehrere Diagramme mit unterschiedlichen \textit{index patterns} angezeigt werden, um die benötigten Metriken zu veranschaulichen. 
So ist es möglich schnell bestimmte Informationen anzuzeigen. 
Für die Visualisierung können alle bekannten klassischen Diagrammtypen genutzt werden. \cite{elasticKibanaVisualisierenAnalysieren}

\subsection{Kibana Query Language (KQL)}
Kibana Query Language (KQL) ist eine Abfragesprache (engl. query language), mit der das Suchen von Daten in großen Datenmengen ermöglicht wird. 
In Kibana wird KQL dazu genutzt, die vorhandenen Logs nach bestimmten Kriterien zu filtern und die gewünschten Daten zu erhalten. 
KQL setzt dabei auf eine leicht verständliche Syntax, damit keine große Einarbeitung nötig ist.
Beim Eintippen in der Suchleiste werden Vorschläge gegeben, um schnelles Filtern zu ermöglichen.
Jedoch wird dafür mindestens eine \textit{Basic License} benötigt.
Sollte KQL nicht gewünscht sein, kann man diese ausschalten und \textit{Lucene} nutzen.
Lucene ist eine Java-Bibliothek, die Such-Features anbietet. 
Dazu gehören das Überprüfen der Syntax, Markieren der Ergebnisse und weitere Funktionen. \cite{apacheApacheLuceneWelcome}
Die Syntax von Lucene sieht so aus: \cite{apacheApacheLuceneQuery}
\begin{lstlisting}
properties.LANR:"1234567" AND properties.level:Info
\end{lstlisting}
Um beispielhaft eine KQL Abfrage vorzuführen, wurde eine Suche in Kibana durchgeführt. 
Dabei können zwei unterschiedliche Methoden genutzt werden. 
Beide Varianten der gleich Abfrage werden hier gezeigt: \\
\begin{lstlisting}
properties.LANR=1234567; properties.level=Info
properties.LANR:1234567 or properties.level=Info
\end{lstlisting}


\section{Logstash}

Logstash ist eines der mächtigsten Tools aus dem Elastic Stack.
Mit Logstash können die Logs gesammelt, geparsed und transformiert werden. 
Jedoch ist ein großes Problem von Logstash, dass es sehr viel Leistung benötigt, betrieben zu werden und sehr viel Wissen um es richtig zu konfigurieren. 
In Abbildung \ref{fig:auslastung} ist ein Auschnitt aus der CPU-Auslastung des Servers, auf dem Logstash installiert wurde. 
Obwohl noch keine Logs gesendet wurden, gab es eine 100\% Auslastung der CPU. 
Das zeigt deutlich, dass Logstash sehr viel Rechenleistung benötigt. 
Nach der deinstallation ist die CPU-Auslastung wieder auf den normal Bereich gesunken. \\
Außerdem ist während der Konfiguration aufgefallen, dass durch die neu geschaffenen Richtlinien, die Transformation und das Parsen der Logs nicht benötigt werden. 
Das Senden der Logs an Elasticsearch wird von Filebeat übernommen. 
Da die Logs durch NLog im JSON-Format gespeichert werden, gibt es keinen Nutzen mehr für Logstash.
Daher wurde entschieden, dass Logstash in diesem Szenario nicht benötigt wird. 


\begin{figure}[H]
    \center 
    \includegraphics[width=1\textwidth]{pictures/auslastungSchnitt.jpg} 
    \caption{CPU-Auslastung }
    \label{fig:auslastung}
\end{figure}

\section{Filebeat}
Filebeat ist die letzte zu installierende Komponente des Elastic Stacks. 
Die Installation von Filebeat muss etwas anders ablaufen als die anderen Komponenten. 
Denn Filebeat wird auf den Windows-Servern der Produktiv- und Test-Systeme installiert. 
Daher muss eine Windows-Installation durchgeführt werden. 
Zu Beginn muss ein Zip-File runtergeladen werden, dass die Basic-Version von Filebeat enthält. 
Nach der Extraktion des Archivs, muss ein PowerShell-Skript als Administrator ausgeführt werden. 
Das PowerShell-Skript \textit{install-service-filebeat.ps1} führt die komplette Installation durch. \\
Nachdem die Installation abgeschlossen ist, muss die Verbindung zu Elasticsearch und Kibana hergestellt werden. 
Dafür muss die Konfigurationsdatei \textit{Filebeat.yml} angepasst werden. 
Zuerst muss eine Verbindung zum Elasticsearch hergestellt werden. 
Das funktioniert mit folgender Zeile in der Konfigurationsdatei:
\begin{lstlisting}
output.elasticsearch:
    hosts: ["http://<server-adresse>:9200"]
\end{lstlisting}
Sollte es mehrere Elasticsearch-Services geben, können diese in das Interval der Hosts mit eingetragen werden. 
So kann bei hoher Last zu mehreren Services gesendet wendet. \\
Damit vordefinierte Index Pattern an Kibana gesendet werden können, muss Kibana auch in der Konfigurationsdatei eingetragen werden.
Der Befehl ist dabei ein bisschen anders: 
\begin{lstlisting}
setup.kibana:
    host: "http://<server-adresse>:5601"
\end{lstlisting}
Damit der Filebeat-Service weiß, welche Logs zu Elasticsearch gesendet werden sollen, müssen noch \textit{inputs} definiert werden.
Dabei können mehrere Inputs definiert werden. 
Die Inputs werden dabei getrennt mit \glqq -\grqq{} angegeben. 
Für die Inputs können verschiedene Konfigurationen definiert werden. 
Damit die Logs der Vierteljahreserklärung gesammelt und gesendet werden, wird diese Konfiguration benötigt: 
\begin{lstlisting}
filebeat.inputs:
- type: log
  enabled: true
  paths: D:\logs\KVWL.PortalVEAddIn\*
  json.keys_under_root: true
  json.add_error_key: true
  fields:
    app_name: VEAddIn
\end{lstlisting}
Zeile 1 definiert, dass jetzt \textit{inputs} folgen. 
Zeile 2 bis 8 sind die Konfigurationen von dem ersten \textit{input}.
Zeile 5 und 6 sind dabei wichtig, denn diese ermöglichen das Einlesen von strukturieren Log-Daten im JSON-Format. 
Zeile 7 und 8 beschreiben selbst definierte Felder in den gesendeten Logs. 
Da können Informationen für alle Logs aus diesem Input ergänzt werden. 
In diesem Fall ist das der Name der Anwendung, der mitgeschickt wird. 
So kann in Kibana nach den einzelnen Anwendungen gefiltert werden. 

\section{Struktur der Logs}

Das CFT Portale arbeitet mit drei Stages: \textit{Prod}, \textit{Test} und \textit{Dev}.
Dabei beschreibt Prod das produktive System, auf denen die Apps für die Mitglieder installiert werden. 
Test ist das Testsystem, auf denen die Software getestet wird, bevor sie ins produktive System deployed wird. 
Dabei ist das Testsystem identisch zum produktiven System aufgebaut.
So können Konfigurationsfehler ausgeschlossen werden. 
Dev spiegelt eine Umgebung wieder, in der das Team neue Features testen kann. 
Die Dev-Umgebung kann sich von der Test- und der Prod-Umgebung unterscheiden. \\
Während in der Dev-Umgebung nur ein Server läuft, wird in der Prod- und Test-Umgebung auf zwei Server gesetzt, die gespiegelt sind. 
Die zwei gespiegelten Server sollen dafür sorgen, dass Ausfälle abgefangen werden können und die Last in Spitzenzeiten besser verteilt wird. \\

Die Abbildung \ref{fig:stages} zeigt die Serverstruktur des CFT Portale.
Dabei kann man alle Server erkennen, auf denen die Provider hosted Apps des CFT Portale installiert sind (PHA-Server) und zusätzlich den zentralisierten Log-Server.
Der zentralisierte Log-Server hat den Namen: \textit{ZLOG1}.
Die anderen Server sind je nach Stage benannt. 
Dabei ist die erste Stage Prod. 
Auf Prod sind zwei Server vorhanden, die gespiegelt sind. 
Dort sind die Apps installiert in der produktiven Umgebung.
Die Servernamen sind: \textit{PHA1} und \textit{PHA2}.
Für die Test-Server werden die Namen \textit{Test1} und \textit{Test2} verwendet.
Dev hat einen Server mit dem gleichen Namen wie die Stage. \\

Auf jedem der in der Abbildung \ref{fig:stages} zu sehenden Server der drei Stages, sind alle Provider hosted Apps des CFT Portale installiert.
Das heißt, dass für einen Server jeweils ein Filebeat-Agent installiert wurde. 
Dieser Agent kümmert sich um die Logs der Apps auf diesem einen Server. 
Das bedeutet, dass jede App fünf mal installiert ist und auch genau so viele Logs von unterschiedlichen Servern schreiben wird. 
Damit die Logs lesbar und strukturiert bleiben, musste eine durchsuchbare Lösung erarbeitet werden. \\ 

\begin{figure}[H]
    \center 
    \includegraphics[width=1\textwidth]{pictures/StagesMitLogs.png} 
    \caption{Stages mit Logs }
    \label{fig:stages}
\end{figure}

Damit die Suche in Kibana effektiv durchgeführt werden kann, werden drei Index Pattern erstellt. 
Jeweils für eine Stage. 
Also sind die drei Patterns dann: \textit{Prod}, \textit{Test} und \text{Dev}.
So kann eine erste schnelle Trennung der Zuständigkeiten erreicht werden. 
Da natürlich pro Stage immer noch eine hohe Anzahl an unterschiedlichen Apps vorhanden ist, wird es schwierig darin die erforderlichen Daten zu finden. 
Die Patterns sollen als erste Filterung genutzt werden, um den Anwendungsfall zu finden. 
Anschließend soll nach den Apps gefiltert werden können. 
Damit dies geschehen kann, muss in der Filebeat Konfiguration für jedes Input ein extra Feld definiert werden in dem der Appname definiert ist. 
Die extra Zeilen für einen Input sehen so aus: 
\begin{lstlisting}
fields:
    app_name: VEAddIn
\end{lstlisting}
Das Beispiel zeigt die Konfigurationen für die Vierteljahreserklärung.
Mit diesen zusätzlichen Feldern ist eine effektive Filterung nach Stages und anschließend nach den Apps möglich. 
Für das Team ist ein häufig auftretender Fall in der produktiven Umgebung, dass es notwendig ist zu wissen auf welchem der beiden produktiven Server (PHA1 und PHA2) die Logs geschrieben wurden. 
Filebeat sendet dafür automatisch die Informationen über den Hostname mit. 
Somit muss das Team zusätzlich zu den zwei Filterungsoptionen noch nach dem \textit{agent.hostname} filtern.


