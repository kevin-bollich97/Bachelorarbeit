\chapter{Evaluation von Log-Management Tools}
In der vorherigen Projektarbeit wurden für das CFT Portale Richtlinien definiert, die in dieser Bachelorarbeit praktisch umgesetzt werden sollen. 
Eine dieser Richtlinien war die Nutzung von einem zentralisierten Logging-Server mithilfe des Elastic Stack. 
Jedoch wurden in der Projektarbeit keine weiteren Tools herangezogen, um zu prüfen, ob der Elastic Stack die beste Alternative ist. \\
In diesem Kapitel werden unterschiedliche Tools, die für das Log-Management genutzt werden können, evaluiert. 
Das Ziel dieser Evaluation ist zu prüfen, ob es eine bessere Alternative für eine zentralisierte Logging Lösung gibt, als den Elastic Stack.
Dafür werden Tools evaluiert, die den kompletten Elastic Stack ersetzen können, aber auch Tools die einzelne Komponenten austauschen können. \\
Das CFT Portale wäre in der Lage weitere Kosten für ein Tool auf sich zu nehmen, sollte es dem Team die Arbeit erleichtern können. 
Daher werden Open-Source und Lizenzpflichtige Tools in dieser Evaluation betrachtet.
Sollten jedoch zwei Tools gleichermaßen die Anforderungen erfüllen und eines der Tools Open-Source sein, dann wird sich für das Open-Source Tool entschieden, um kosten zu sparen. \\
Damit eine Evaluation erfolgen kann, müssen Anforderungen aufgestellt werden. 
Die Anforderungen sollen dabei helfen eine Entscheidung bezüglich der Tools treffen zu können. 
Denn Tools die diese Anforderungen nicht erfüllen können, werden nicht weiter betrachtet.
Im nächsten Abschnitt werden die Anforderungen definiert.

\section{Anforderungen an die Log-Management Tools}
\label{kap:anforderungenTools}
In diesem Abschnitt werden Anforderungen für die zentralisierten Logging Tools definiert. 
Die Anforderungen helfen bei der Entscheidung, ein passendes Tool für das CFT Portale auszuwählen. 
Daher wurden in Absprache mit dem Team einige Anforderungen definiert, die das zukünftige Tool haben sollte. 
Für das CFT Portale spielt Wartung eine wichtige Rolle, daher werden einige Anforderungen sich auf den Wartungsaufwand beziehen. \\

Da das KV-Netz Sicherheitstechnisch stark abgeschirmt ist, kommt eine Cloud Lösung nicht in Frage. 
Das bedeutet, dass das Tool eine Selbstorganisierte Lösung bieten muss. \\
Durch die Menge an Anwendungen die das CFT Portale betreuen muss, ist es wichtig, dass das Tool die einzelnen Logs entweder von den unterschiedlichen Maschinen selbst einsammeln kann oder ein Senden von den Anwendungen heraus möglich ist. 
Das installieren weiterer Log-Agenten die für das schicken der Logs zuständig wäre sollte vermieden werden. 
Da sonst weiterer Wartungsaufwand entstehen würde. \\
Da das CFT Portale sich um keine Datenbanken kümmert ist der aktuelle wissensstand des Teams eher allgemein vorhanden. 
Denn das Team übernimmt in der Regel die Entwicklung von Provider-hosed Apps im SharePoint Umfeld. 
Damit das Team also erfolgreich mit den Datenbanken arbeiten kann, müssen Schulungen absolviert werden. 
Daher ist eine wichtige Anforderung die Speicherung der Logs. 
Das ausgewählte Tool muss eine Möglichkeit anbieten die Logs zu speichern. \\
Ein wichtiger Punkt ist die Analyse und Anzeige von Logs. 
Damit ist eine Oberfläche gemeint, die intuitiv benutzt werden kann, um die Logs anzusehen und zu Analysieren. 
Jedoch sollte in dem Tool auch die Möglichkeit bestehen, Logs zu Filtern und zu durchsuchen. \\
Im CFT Portale sind Linux- und Windows Server im Betrieb. 
Jedoch möchte das Team das Tool gerne auf einer Linux Maschine installieren. 
Da dort das updaten von neuen Versionen einfacher funktioniert und der wissensstand des Teams da komplett gegeben ist. \\

Das waren die Vorgaben die Vom CFT Portale für ein Tool definiert wurden. Hier nochmal eine kleine Aufzählung der einzelnen Anforderungen:

\begin{itemize}
    \item Selbstorganisierte Lösung (Kein CLoud)
    \item Einsammeln von Logs aus unterschiedlichen Anwendungen 
    \item Speicherung von Logs ohne externe Datenbank
    \item Anzeige und Analyse von Logs 
    \item Filtern und Dursuchen von Logs 
    \item Installation auf Linux Server 
\end{itemize}

\section{Log-Management Tools}

In der Projektarbeit wurde der Elastic Stack in seiner Funktionsweise und dessen Möglichkeiten  schon ausreichend vorgestellt. 
Daher wird in diesem Kapitel hauptsächlich auf die neu zu evaluieren Tools eingegangen. 
Alle Tools werden hier einmal vorgestellt mit all ihren Vor- und Nachteilen.
Eine Bewertung der Tools wird in Kapitel \ref{kap:bewertungTools} durchgeführt.
Bevor die Tools evaluiert werden können, musste eine vorauswahl getroffen werden, um potenzielle Tools finden zu können. 
Dafür wurden eine Vielzahl an Tools betrachtet und nach den Anforderungen in Kapitel \ref{kap:anforderungenTools} ausgewählt. 



\subsection{Graylog}
Graylog ist ein Open-Source Log-Management Tool. 
Dessen Motto ist:
\begin{quote}
    \glqq  less cost, more performance\grqq \cite{graylogIndustryLeadingLog}
\end{quote}

Das Tool setzt auf Performance.
Die Funktionalitäten des Tools beziehen sich auf das Sammeln, verbessern, Speichern und der Analyse von Logs. 
In Graylog kann man eigene Dashboards erstellen und individuell anpassen. 
Das Dashboard wird mithilfe von Suchabfragen definiert.
Damit nicht jeder Mitarbeiten sich mit den Suchabfragen beschäftigen muss, können die Dashboards untereinander geteilt werden. 
Graylog bietet zusätzlich vordefinierte Dashboards an, die genutzt werden können. \\
Mithilfe von Graylog können unmengen an Logs gespeichert werden.
Daher ist die Suche in Großen Datenmengen essenziell. 
In Graylog werden die Logs beim Speichern indiziert, um eine effiziente Suche zu ermöglichen. 
Die Daten werden beim Speichern geprüft. 
Bei der Prüfung wird die Struktur genauer untersucht, um festzustellen, ob die Struktur in Ordnung ist.
Wenn die Struktur nicht in Ordnung ist, wird sie verbessert. \\
Die Architektur von Graylog ermöglicht eine multi-threaded Suche. 
Jede Suche nutzt dabei mehrere Prozessoren, um möglichst effizient zu sein. 
Die Suche in Graylog ist dabei einfach aufgebaut. 
Einfache Boolean Operationen werden für die Suche genutzt. 
Die dazu benötigten Felder werden durch einfaches klicken ausgewählt.
Damit muss keine neue Suchsprache erlernt werden und kann von nicht Fachpersonal genutzt werden. \cite{graylogIndustryLeadingLog} \\

Wenn mehr benötigt wird, als die Open Source Version anbietet, dann kann Graylog als Enterprise Variante gekauft werden. 
Bei der Enterprise Variante werden Support und zusätzliche Funktionen angeboten.
Der genaue Vergleich der beiden Varianten kann in Abbildung \ref{fig:vergleichGraylogOSvsE} im Anhang \ref{anhang:vergleichGraylogOSvsE} gesehen werden.
Zu dem Support gehört Hilfe zu allen Graylog bezogenen Fragen, jedoch bietet Graylog zusätzlich Support für Elasticsearch, MongoDB und Oracle Java SE 8 (oder OpenJDK 8).
Sie bieten diesen Support an, weil Graylog diese Produkte benötigt, um laufen zu können. 
Das bedeutet, dass diese Produkte zusätzlich auf der zu installierenden Maschine installiert werden. 
Zum Thema der zu installierenden Maschine ist wichtig zu beachten, dass Graylog nur auf Linux-basierten Betriebssystemen installiert werden kann. \\
Die Graylog Enterprise variante kann bis zu 5 GB/Tag kostenlos erworben werden. 
Für so kleine Datenmengen ist es daher Ratsam direkt auf die Enterprise Variante zu setzen. \cite{graylogGraylogOpenSource} \\

Damit Graylog funktionieren kann muss weitere Software auf der Maschine installiert werden. 
Das bewirkt, dass der Aufwand für das Updaten des Tools zu Problemen führen kann. 
Beim Betrieb von Graylog muss darauf geachtet werden, dass die Versionen der Tools passen. 
Das sorgt dafür, dass der Wartungsaufwand sehr Hoch ist. \\
Abließend können die folgenden Vor- und Nachteile für Graylog zusammengefasst werden: \\

\begin{itemize}
    \item Vorteile: 
    \begin{itemize}
        \item Open Source (Enterprise auch möglich)
        \item Sehr performant durch multi-threaded Suche und indizierung
        \item Speichern großer Datenmengen möglich
    \end{itemize}
     
    \item Nachteile: 
    \begin{itemize}
        \item Notwendige Installation von weiterer Software
        \item Durch extra Software Updates Problematisch
        \item Installation nur auf Linux Maschinen
    \end{itemize}
\end{itemize}


Sematext? 
\subsection{Loggly}
\subsection{Splunk}
\subsection{LogDNA}

\subsection{Fluentd}

Fluentd ist ein Open Source data Collector, der es den Anwendern ermöglichen soll alles zu loggen. 
Das heißt Fluentd sammelt Daten von einer Stelle und bringt sie in gewünschter Form in das Ziel. 
Also ist Fluentd kein Tool um zentralisiertes Logging zu ermöglichen, sondern nur ein Tool das beim zentralisierten Logging behilflich ist. 
Mithilfe von Fluentd können Datenströme einheitlich gestaltet werden. 
Ein Beispiel dafür sieht an in Abbildung \ref{fig:fluentdVorherNachher}.
Im vorher Bild ist es Schwer zu erkennen wie die Daten versendet werden, im nachher Bild ist es einfach zu erkennen das alle Datenströme durch Fluentd gelangen müssen. \Cite{fluentdFluentdOpenSource} \\

Fluentd versucht soweit es möglich ist, die Daten zu strukturieren. 
Dabei werden die Daten in JSON gespeichert. 
Somit kann Fluentd die Daten einheitlich verarbeiten. 
Zum Verarbeiten gehören das Sammeln, Filtern, Puffern und die Weitergabe der Logs über verschiedene Quellen und Ziele hinweg. 
Für weitere Funktionalitäten können Lösungen von der Community genutzt werden. 
Das wird durch die Steckbare Architektur von Fluentd ermöglicht. 
Fluentd ist in einer Kombination von C und Ruby entwickelt worden. 
Deswegen benötigt es nur wenig System Ressourcen um zu Funktionieren.
Die standard Version von Fluentd ohne weitere Komponenten benötigt ungefähr 30-40 MB Speicher. \cite{projectWhatFluentdFluentd}

Die größten Vorteile von Fluentd sind die Menge an Plugins die verfügbar sind und die Performance. 
Außerdem verbraucht Fluentd sehr wenig Speicher. 
Der größte Nachteile ist der Zwang nach Strukturierten Daten, damit ist gemeint, dass es nicht so flexibel möglich ist zu entscheiden wie die Logs auszusehen haben. 

\begin{figure}[H]
    \center 
    \includegraphics[width=1\textwidth]{pictures/Fluentd.PNG} 
    \caption{Fluentd vorher und nachher Vergleich \cite{projectWhatFluentdFluentd}}
    \label{fig:fluentdVorherNachher}
\end{figure}




Logagent? 

https://sematext.com/blog/logstash-alternatives/


\section{Bewertung der Tools}
\label{kap:bewertungTools}